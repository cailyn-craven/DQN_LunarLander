{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAhmlTD4ogSp",
    "outputId": "fb49331b-9adb-4742-d431-43562cad9619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: box2d-py in /Users/cailyncraven/opt/anaconda3/lib/python3.7/site-packages (2.3.8)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install box2d-py\n",
    "import random\n",
    "import sys\n",
    "from time import time\n",
    "from collections import deque, defaultdict, namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import torch as T \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Familiar with the State Space and Actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_Ht_QUmoiVX",
    "outputId": "aa99bc19-aabd-4b72-f366-b0e53ccfd1b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lsNgB7domTe",
    "outputId": "cdd59fa8-7213-45ce-94d0-35d4959c6cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "Box(-inf, inf, (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "# inspect action space and state space\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4O1UfRnvR-CK",
    "outputId": "a83ed949-4a0a-467e-beeb-13b30c4e20ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 8, action size: 4\n"
     ]
    }
   ],
   "source": [
    "# Get state and action sizes\n",
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "print('State size: {}, action size: {}'.format(num_states, num_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent \n",
    "This is based on the class notebook introducing the Cartpole toy problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nVsHJ_BxopvD"
   },
   "outputs": [],
   "source": [
    "# Agent that takes random actions\n",
    "max_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXmTLix9ouGt",
    "outputId": "d1580b8b-f655-44fa-9ab3-96fdcc63c6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20,  score: -195.43262783442657\n",
      "Episode 40,  score: -263.76802578179445\n",
      "Episode 60,  score: -383.4539026596413\n",
      "Episode 80,  score: -275.5699497352973\n",
      "Episode 100,  score: -121.44648947414903\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "actions = range(env.action_space.n)\n",
    "for i in range(1, max_episodes+1):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    while True:\n",
    "        action = np.random.choice(actions)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        if done:\n",
    "            if i % 20 == 0:\n",
    "                print('Episode {},  score: {}'.format(i, score))\n",
    "            break\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "-KuNpuD6oyBw",
    "outputId": "350fb8d4-99c2-451b-d142-e3bf6419ceba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show random agent's performance\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(max_episodes), scores)\n",
    "plt.title('Performance of Random Agent')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1v8pj7Tgo48m",
    "outputId": "462f508b-5a48-48c8-9318-944c04e3b0ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score of random agent over 100 episodes: -171.97\n"
     ]
    }
   ],
   "source": [
    "# Average score\n",
    "print('Average score of random agent over {} episodes: {:.2f}'.format(max_episodes, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Deep Q-learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Brx8vRq4o6dZ"
   },
   "outputs": [],
   "source": [
    "# Use cuda if available else use cpu\n",
    "device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhCil_3SJD93"
   },
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ADAS1-bQJBBX"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters: set these up as global variables\n",
    "# so I can test tuning them frm here \n",
    " \n",
    "BUFFER_SIZE = 50000 # Replay memory size\n",
    "BATCH_SIZE = 64     # Number of experiences to sample from memory\n",
    "GAMMA = 0.99        # Discount factor\n",
    "LR = 1e-4           # Q Network alpha learning rate\n",
    "UPDATE_EVERY = 4    # How often to update Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IN1yZ-VVI6zO"
   },
   "outputs": [],
   "source": [
    "MAX_EPISODES = 2000  # Max number of episodes to play\n",
    "MAX_STEPS = 1000     # Max steps allowed in a single episode/play\n",
    "ENV_SOLVED = 200     # Average Reward where an environment is considered solved\n",
    "PRINT_EVERY = 100    # After this many episodes, print the progress \n",
    "\n",
    "# Epsilon Decay \n",
    "\n",
    "EPS_START = 1.0      # Default/starting value of eps\n",
    "EPS_DECAY = 0.999    # Epsilon decay rate\n",
    "EPS_MIN = 0.01       # Minimum epsilon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEmUy8FmYGA4"
   },
   "source": [
    "## Action Value Network\n",
    "This class implements the **function approximator** used in the agent. In this case, the function approximator is a ***neural network***. We are using a neural network for approximating the action-value function in a control problem. Neural networks can also be used as the function approximator for policy evaluation problems. When using a neural network to approximate a state-value function, the output layer only includes one unit. For an action-value function, the number of units in the output layer needs to match the number of actions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "69F0Jo6uo-ci"
   },
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    LinearClassifier that derives from nn.Module\n",
    "    the reason that we derive PyTorch classes from nn.Module\n",
    "    is because that gives us access to parameters of deep neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, num_states, num_actions, seed):\n",
    "        \"\"\"\n",
    "        takes number of states and number of actions as input\n",
    "        use a seed for reproducibility: \n",
    "        https://pytorch.org/docs/stable/notes/randomness.html\n",
    "        whenever we are deriving one class from another, \n",
    "        we want to use the super constructor \n",
    "        \"\"\"\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        # declare layers of deep neural network \n",
    "        # we have three fully connected linear layers \n",
    "        # input layer, hidden layer, and output layer \n",
    "        # You can use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA):\n",
    "        self.seed = T.manual_seed(seed)\n",
    "        # torch.nn.Linear(in_features: int, out_features: int) \n",
    "        # we have num_states (which is 8 in this case) as the input \n",
    "        self.fc1 = nn.Linear(num_states, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        \"\"\"\n",
    "        we have n_actions as output for this layer \n",
    "        because we want to calculate estimate for Q which is a state, action pair\n",
    "        Q is a state, value action function, \n",
    "        we want to get out the value of each action for that state \n",
    "        dimensionality must correspond to number of actions for have for our environment\n",
    "        \"\"\"\n",
    "        self.fc3 = nn.Linear(128, num_actions) \n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device) \n",
    "    # PyTorch handles backpropagation algorithm for us,\n",
    "    # but we need to define own forward propagation algorithm    \n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        pass data through each linear layer and activate it \n",
    "        with the relu function \n",
    "        returns actions tensor with shape [4] \n",
    "        \"\"\"\n",
    "        layer1 = F.relu(self.fc1(state))\n",
    "        layer2 = F.relu(self.fc2(layer1))\n",
    "        actions = self.fc3(layer2)\n",
    "        #print(actions.shape)\n",
    "        return actions        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLVtbynOPpuO"
   },
   "source": [
    "## The Agent's Memory\n",
    "We need memory of:\n",
    "+ States\n",
    "+ Actions\n",
    "+ Rewards\n",
    "+ New States \n",
    "+ Dones (target is different when new state is terminal compared to not terminal) \n",
    "\n",
    "* Uniformly sample memories up to most recent so every memory has an equal probability of being sampled. \n",
    "* We shouldn't repeat memories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL_Oa015QXiL"
   },
   "source": [
    "## Implemenation Tips:\n",
    "* Can use dequeues or numpy arrays \n",
    "* We do need to return numpy arrays at the end anyway. \n",
    "* Have separate arrays for each thing we are storing so there isn't confusion later when we go to access the agent's memory. \n",
    "* We could also reurn PyTorch tensors. A downside of this is that if I decided I wanted to switch the project to TensorFlow or Keras, I would need to rewrite part of the agent's memory. \n",
    "These tips are from the Udemy Course Modern Reinforcement Learning: Deep Q Learning in PyTorch where Phil Tabor implements a Deep Q Learning Agent to play Pong. \n",
    "https://www.udemy.com/course/deep-q-learning-from-paper-to-code/learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxvtjeczra5i"
   },
   "source": [
    " We can use a more efficient approach for updating value functions.  The idea behind Dyna is to learn a model using sampled experience, obtain simulated experience from the model, and improve the value function using the simulated experience.\n",
    "\n",
    "**Experience replay** is a simple method that can get some of the advantages of Dyna by saving a buffer of experience and using the data stored in the buffer as a model. This view of prior data as a model works because the data represents actual transitions from the underlying MDP. Furthermore, as a side note, this kind of model that is not learned and simply a collection of experience can be called non-parametric as it can be ever-growing as opposed to a parametric model where the transitions are learned to be represented with a fixed set of parameters or weights.\n",
    "\n",
    "ReplayBuffer includes two main functions: append() and sample(). append() adds an experience transition to the buffer as an array that includes the state, action, reward, terminal flag (indicating termination of the episode), and next_state. sample() gets a batch of experiences from the buffer with size minibatch_size.\n",
    "\n",
    "You will use the append() and sample() functions when implementing the agent.\n",
    "These notes about **replay buffers** are based on the Coursera Course, \"A Complete Reinforcement Learning System Capstone\" by the University of Alberta. \n",
    "https://www.coursera.org/learn/complete-reinforcement-learning-system/lecture/ToRFI/meeting-with-niko-choosing-the-learning-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NodKWpZm8KCy"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    \"\"\"\"\n",
    "    this generic replay buffer comes from Phil Tabor:\n",
    "    https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code/blob/master/DQN/replay_memory.py\n",
    "    to adapt this to my project, one of the biggest hangups was getting the numpy arrays\n",
    "    to have the correct dimensions for when they are turned into PyTorch tensors later on\n",
    "    one of my biggest challenges with PyTorch was choosing the correct datatype \n",
    "    so I appreciate the datatypes Tabor carefully chose for the NumPy arrays\n",
    "    a Replay Buffer typically has two key functions: append and sample \n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size, input_shape, n_actions, seed):\n",
    "        \"\"\"\n",
    "        constructor for the replay buffer takes \n",
    "        buffer_size, input shape which corresponds to state space dimensions,\n",
    "        number of actions, and seed to that results are reproducible \n",
    "        \"\"\"\n",
    "        self.seed = random.seed(seed)\n",
    "        self.mem_size = buffer_size\n",
    "        \"\"\"\n",
    "        one of the design decisions that needed to be made\n",
    "        was how to handle sampling for the episodes the agent \n",
    "        ran before filling up the replay buffer \n",
    "        the memory counter helps make that decision\n",
    "        use memory counter with modulo on the size of the replay \n",
    "        buffer also helps overwrite old experiences with new experiences \n",
    "        \"\"\"\n",
    "        self.mem_counter = 0\n",
    "        # the numpy arrays for state_memory and new_state memory\n",
    "        # both have shape (64, 8)\n",
    "        # 64 is the batch size, 8 is the size of the state space \n",
    "        self.state_memory = np.zeros((self.mem_size, input_shape),\n",
    "                                     dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, input_shape),\n",
    "                                         dtype=np.float32)\n",
    "        # later these numpy arrays will get turned into PyTorch tensors\n",
    "        # it is critical that the batches returned have size (64, 1), note: 64 is the batch size\n",
    "        # add a 1 dimension to the array here so that the batch dimension will ultimately be correct\n",
    "        self.action_memory = np.zeros((self.mem_size, 1), dtype=np.int64)\n",
    "        #self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.reward_memory = np.zeros((self.mem_size, 1), dtype=np.float32)\n",
    "        # led to trying to do subtraction with bool type \n",
    "        # changed terminal_memory array from type bool to int32 \n",
    "        # due to how I handle my masking later on in the loss calculation \n",
    "        # self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "        self.terminal_memory = np.zeros((self.mem_size, 1), dtype=np.int32)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        can consider this the append feature \n",
    "        append() adds an experience transition to the buffer as an array \n",
    "        that includes the state, action, reward, \n",
    "        terminal flag (indicating termination of the episode), and next_state.\n",
    "        \"\"\"\n",
    "        # modulo the memory counter with size of the buffer to find the index \n",
    "        # add state, action, reward, next_state, and done numeric variables\n",
    "        # into the associated numpy array at that specific index \n",
    "        index = self.mem_counter % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = next_state\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "        # increment the memory counter every time the append function is used \n",
    "        self.mem_counter += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        \"\"\"\n",
    "        sample() gets a batch of experiences from the buffer with size batch_size \n",
    "        \"\"\"\n",
    "        #max_mem = min(self.mem_counter, self.mem_size)\n",
    "        max_mem = self.mem_size \n",
    "        # use random choice to randomly select the samples \n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "        # create numpy arrays made up only of the randomly selected batch \n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        next_states = self.new_state_memory[batch]\n",
    "        dones = self.terminal_memory[batch]\n",
    "        # return the numpy arrays with the batches \n",
    "        return states, actions, rewards, next_states, dones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqcfT343k1hf"
   },
   "source": [
    "## The Agent Class \n",
    "Innovation:\n",
    "+ An **online network** that gets updated with **gradient descent** in addition to a **target network** that handles calculation of the target values. \n",
    "+ The **target network** only gets updated periodically with the weights of the **online network.** \n",
    "+ We also have a **replay buffer** that we use to sample the agent's history. \n",
    "+ Agent needs to be able to choose action, copy target network, decrement epsilon, learn and store memories \n",
    "+ Also need to load and save models (interface with the Deep Q Network) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3QKzZU5JrEBq"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, num_states, num_actions, seed):\n",
    "    #def __init__(self, lr, num_states, num_actions, seed):\n",
    "        \"\"\"\n",
    "        Takes in number of states (int), number of actions(int), \n",
    "        Using a seed(int) for reproducibility. \n",
    "        \"\"\"\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.seed = random.seed(seed)\n",
    "        # Initialize the separate q networks \n",
    "        # We have one Q network for the target and one for prediction \n",
    "        self.q_network = DeepQNetwork(num_states, num_actions, seed).to(device)\n",
    "        self.fixed_network = DeepQNetwork(num_states, num_actions, seed).to(device)\n",
    "        \"\"\"\n",
    "        Adam is a type of stochastic gradient descent with momentum\n",
    "        it is an adaptive learning rate algorithm \n",
    "        for the Deep Q Learning algorithm, the paper does opt for RMSprop optimizer\n",
    "        self.parameters() comes from nn.module and tells us what we want to optimize \n",
    "        \"\"\"\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters())\n",
    "        # initialize a ReplayBuffer instance \n",
    "        self.memory = ReplayBuffer(BUFFER_SIZE, num_states, num_actions, seed)\n",
    "        # initialize a timestep counter, this is used to track when to update the network \n",
    "        self.timestep = 0\n",
    "\n",
    "    def sample_memory(self):\n",
    "        # this function is called to sample the replay buffer \n",
    "        # unpack the tuple of numpy arrays returned \n",
    "        state, action, reward, new_state, done = self.memory.sample_buffer(BATCH_SIZE)\n",
    "        # convert the numpy arrays into PyTorch tensors \n",
    "        # the state and new_state tensors have shape [64, 8]\n",
    "        # the rest of the arrays have tensor shape [64, 1]\n",
    "        # this shape is why it was important to reshape the numpy arrays\n",
    "        # in the ReplayBuffer class \n",
    "        states = T.tensor(state).to(self.q_network.device)\n",
    "        actions = T.tensor(action).to(self.q_network.device)\n",
    "        rewards = T.tensor(reward).to(self.q_network.device)\n",
    "        new_states = T.tensor(new_state).to(self.q_network.device)\n",
    "        dones = T.tensor(done).to(self.q_network.device)\n",
    "      \n",
    "        # return the PyTorch tensors \n",
    "        return (states, actions, rewards, new_states, dones)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def learn(self, experiences):\n",
    "        \"\"\"\n",
    "        Takes in experiences which is a tuple with numpy arrays\n",
    "        which are the batches that the agent samples \n",
    "        \"\"\"\n",
    "        # we don't want to start learning until the replay buffer \n",
    "        # is filled up, for example it would be problematic \n",
    "        # to try to take a sample of size 64 from buffer with only 1 experience in it\n",
    "        if dqn_agent.memory.mem_counter < BATCH_SIZE:\n",
    "          return \n",
    "        \"\"\"\n",
    "        when training a neural network, models are able to increase accuracy \n",
    "        through gradient descent. Gradient descent is the process of minimizing loss\n",
    "        by tweaking the weights and biases in model. \n",
    "        This is a good best practice before doing backpropagation because \n",
    "        PyTorch accumulates gradients on subsequent backward passes.\n",
    "        See Stack overflow post (Why do we need to call zero_grad)\n",
    "        TODO: look the placement of where zero_grad should occur \n",
    "        \"\"\"   \n",
    "\n",
    "        # break apart tuple experiences into these tensors \n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        # get the action with the max Q-value \n",
    "        # I really struggled with getting the torch tensor dimensions correct for this section\n",
    "        # utilized this resource: https://www.datahubbs.com/deep-q-learning-101/\n",
    "        # the PyTorch max function returns a tuple with the maximum value and index of the maximum value\n",
    "        # use [0] to just get the max value for each row \n",
    "        # call detach to make sure that these values don't update the target network \n",
    "        # when we call loss.backward() and optimizer.step() \n",
    "        q_vals_next = T.max(self.fixed_network(next_states), dim=-1)[0].detach()\n",
    "        # the q_vals_next tensor has shape [64]\n",
    "        # we need to get the tensor to have shape [64, 1]\n",
    "        # use unsqueeze[1] to add that extra dimension \n",
    "        max_action_vals = q_vals_next.unsqueeze(1)\n",
    "        # If done just use reward, else update Q_target with discounted action values\n",
    "        #  The qvals_next are set to 0 at terminal states because there are no future rewards to discount.\n",
    "        # Then we combine all of these together with the reward and the discount factor to get the q_target\n",
    "        q_target = rewards + (GAMMA * max_action_vals * (1 - dones))\n",
    "        # To update the network, we need to get the Q-values for the actions that we actually took, \n",
    "        # use PyTorch’s gather() function to subset Q-values appropriately.\n",
    "        q_expected = T.gather(self.q_network(states), 1, actions)\n",
    "        \n",
    "        \n",
    "        # Calculate loss\n",
    "        # for Deep Learning, we want to use something \n",
    "        # like nn.MSELoss()\n",
    "        loss = F.mse_loss(q_expected, q_target)\n",
    "        \"\"\"\n",
    "        when training a neural network, models are able to increase accuracy \n",
    "        through gradient descent. Gradient descent is the process of minimizing loss\n",
    "        by tweaking the weights and biases in model. \n",
    "        This is a good best practice before doing backpropagation because \n",
    "        PyTorch accumulates gradients on subsequent backward passes.\n",
    "        See Stack overflow post (Why do we need to call zero_grad)\n",
    "        https://stackoverflow.com/questions/44732217/why-do-we-need-to-explicitly-call-zero-grad/44732271\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Update fixed weights\n",
    "        self.update_fixed_network(self.q_network, self.fixed_network)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def update_fixed_network(self, q_network, fixed_network):\n",
    "        \"\"\"\n",
    "        update fixed network by copying weights from Q network \n",
    "        zipping together source and target parameters will make \n",
    "        it possible to iterate over and copy the weights from the q network\n",
    "        to the fixed network \n",
    "        \"\"\"\n",
    "        \n",
    "        for source_parameters, target_parameters in zip(q_network.parameters(), fixed_network.parameters()):\n",
    "            # copy weights from q network to fixed network \n",
    "            target_parameters.data.copy_(source_parameters.data)\n",
    "        \n",
    "        \n",
    "    def act(self, state, epsilon=0.0):\n",
    "        \"\"\"\n",
    "        Choose the action using an Epsilon Greedy Action Selection Strategy\n",
    "        takes environment state as input \n",
    "        random.random() returns a number between 0.0 and 1.0 \n",
    "        https://stackoverflow.com/questions/33359740/random-number-between-0-and-1-in-python\n",
    "        if greater than epsilon, take greedy action \n",
    "        returns integer corresponding to action \n",
    "        \"\"\"\n",
    "        if random.random() > epsilon:\n",
    "          \"\"\"\n",
    "          make sure the state is Pytorch tensor \n",
    "          that is sent to actual kuda device \n",
    "          Pytorch is quite particular about datatypes of tensors passed in \n",
    "          device is a property of the LinearDeepQNetwork\n",
    "           set dtype of float to be extra cautious about making sure everything matches up\n",
    "          \"\"\"\n",
    "          state = T.tensor(state, dtype=T.float).to(device)\n",
    "          \"\"\"  \n",
    "          looked at this post about eval vs train mode\n",
    "          https://jamesmccaffrey.wordpress.com/2019/01/23/pytorch-train-vs-eval-mode/\n",
    "          if you use batch normalization or dropout,\n",
    "          you must set model to model evaluation mode when computing model output values\n",
    "          then you set back to default training mode when done \n",
    "          neural network doesn't use batch normalization or droput out,\n",
    "          but set this up to somewhat future proof it\n",
    "          \"\"\"\n",
    "          self.q_network.eval()\n",
    "          with T.no_grad():\n",
    "              actions = self.q_network.forward(state)\n",
    "          self.q_network.train()\n",
    "          \"\"\"\n",
    "          take argmax of tensor actions \n",
    "          need to dereference it with a .item function\n",
    "          this is a nuance of the Pytorch framework,\n",
    "          when you feed forward state through the Q network,\n",
    "          you don't get back a numpy array, you get back a tensor\n",
    "          a tensor won't serve as appropriae input to OpenAI Gym's environment\n",
    "          the .item function gets the numpy array out of it \n",
    "          \"\"\"\n",
    "          action = T.argmax(actions).item() \n",
    "        # otherwise choose a random action \n",
    "        else: \n",
    "          action = np.random.choice(self.num_actions)\n",
    "        return action \n",
    "\n",
    "    def checkpoint(self, filename):\n",
    "        T.save(self.q_network.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Game Loop \n",
    "Follows that standard OpenAI Gym form like the class Cartpole notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T97XWIeqpevZ"
   },
   "outputs": [],
   "source": [
    "# instantiate a DQNAgent \n",
    "dqn_agent = DQNAgent(num_states, num_actions, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqn8K6y7piF3",
    "outputId": "1d79494b-4d60-4f44-f029-af79e459b116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved game in 912 episodes, average score: 252.01"
     ]
    }
   ],
   "source": [
    "# keep track of how long it takes to get to max number of episods \n",
    "start = time()\n",
    "# initialize list to keep track of scores \n",
    "scores = []\n",
    "# Maintain a list of last 100 scores\n",
    "# An environment is considered to be solved\n",
    "# or not based on average reward for past 100 episodes\n",
    "scores_window = deque(maxlen=100)\n",
    "epsilon = EPS_START\n",
    "#env = wrappers.Monitor(env, \"/Users/cailyncraven/Documents/CSPB_3202/dqn-video7\", video_callable=lambda episode_id: True, force=True)\n",
    "for episode in range(1, MAX_EPISODES + 1):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    # adding this in \n",
    "    timestep = 0 \n",
    "    for step in range(MAX_STEPS):\n",
    "        action = dqn_agent.act(state, epsilon)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        dqn_agent.memory.add(state, action, reward, next_state, done)\n",
    "        timestep += 1 \n",
    "        if timestep % UPDATE_EVERY == 0:\n",
    "            sampled_experiences = dqn_agent.sample_memory()\n",
    "            dqn_agent.learn(sampled_experiences)     \n",
    "        state = next_state        \n",
    "        score += reward        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        epsilon = max(epsilon * EPS_DECAY, EPS_MIN)\n",
    "        #if episode > MAX_EPISODES - 6:\n",
    "        #    env = wrappers.Monitor(env, \"/Users/cailyncraven/Documents/CSPB_3202/dqn-video10\", video_callable=lambda episode_id: True, force=True)\n",
    "        if episode % PRINT_EVERY == 0:\n",
    "            mean_score = np.mean(scores_window)\n",
    "            print('\\r Episode {}/{}, average score:{:.2f}'.format(episode, MAX_EPISODES, mean_score), end=\"\")\n",
    "        if score >= ENV_SOLVED:\n",
    "            mean_score = np.mean(scores_window)\n",
    "            print('\\rSolved game in {} episodes, average score: {:.2f}'.format(episode, mean_score), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            dqn_agent.checkpoint('solved_200.pth')\n",
    "            break\n",
    "            \n",
    "    scores_window.append(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "end = time()    \n",
    "print('Took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKqcp1vgpmxw"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        action = dqn_agent.act(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        state = next_state        \n",
    "        score += reward        \n",
    "        if done:\n",
    "            break\n",
    "    print('episode: {} scored {}'.format(i, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89EJAgWE0yPX"
   },
   "outputs": [],
   "source": [
    "dqn_agent.checkpoint('solved_200.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBpmVqOb01Bz"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(scores)\n",
    "# Add a trend line \n",
    "plt.plot(pd.Series(scores).rolling(100).mean())\n",
    "plt.title('DQN Training')\n",
    "plt.xlabel('# of Episodes')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Ziiwloa3Q2k"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka0MwfZCpU9M"
   },
   "source": [
    "## Metaparameter Choices\n",
    "+ Function Approximator \n",
    "+ Optimizer Choices for updating action values\n",
    "+ How to do exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQKbkbM0s__F"
   },
   "source": [
    "## For Function Approximator:\n",
    "+ It would make sense to start simple with something like Tile Coder: Here we have 8 dimensions. If we wanted to use 10 tiles per dimension, that would be 10^8. We could easily end up with 100 million features. \n",
    "+ Because of this it makes sense to use a **neural network** instead. This should be sufficiently powerful for the LunarLander problem. You get to choose how many neurons there will be. Adding more neurons to a hidden layer gives more representational power, but the more nodes you add, the more parameters there are to learn. Neural Networks can be viewed as constructing featurs. Neural networks are non-linear functions of state.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr_VxBPItScp"
   },
   "source": [
    "## Choose Activation Function \n",
    "We could use a sigmoidal function like **tanh**. These have some issues with sauration. There can be the **vanishing gradient issue.** A common popular choice is **ReLUs**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgwHJtBvuh0E"
   },
   "source": [
    "## How are we going to train the network?\n",
    "Using vanilla **stochastic gradient descent**, will likely be too slow for this project so what other options do we have? \n",
    "+ We could use **adagrad**. The downside of this is that it decays values down to zero. This can be problematic for non-stationary learning. \n",
    "+ **RMSProp** uses information about the curvature of the plots to improve the descent step. \n",
    "+ We do also want to incorporate **momentum** to speed up learning. **Adam** is a good choice because it combines the curvature information from RMSProp and momentum. \n",
    "+ What **exploration strategy** will we use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-L7wAUU04dO"
   },
   "source": [
    "+ **Optimistic Initial Values**: this would be a good choice if we were using a linear function approximator with non-negative features. We are using a neural network so it is difficult to maintain optimistic values, and they are unlikely to be effective. \n",
    "+ We can also consider **Epsilon Greedy.** This is easy to straightforward to implement. The downside is that its exploration ignores whatever information the action values may have. It is equally likely to explore an action with a really negative value as an action with a moderately negative value. \n",
    "+ **Softmax**: a good choice because the probability of selecting an action is proportional to the value of the action. This way we are less likely to explore actions that we think are really bad. There are a few things to consider when using sofmax on action values. \n",
    "  + use **tau** as a temperature parameter. If tau is large, then the agent is more stochastic. For a very large tau, the agent behaves almost like a uniform random policy. For a very small tau, the agent mostly selects the greedy action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxOGg37B3rH0"
   },
   "source": [
    "To brainstorm some of the key choices for an agent, we can reason through what choices would make the most sense. Other choices like specific step sizes in the optimizer and exploration parameters like the temperature can be less obvious to simply select. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKwkoyikqXci"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PrettyDarnGood_Iteration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
